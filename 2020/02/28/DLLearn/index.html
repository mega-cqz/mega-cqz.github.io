<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>深度学习 | 世界で一番おひめさま</title><meta name="description" content="深度学习"><meta name="keywords" content="深度学习,面试"><meta name="author" content="Cqz"><meta name="copyright" content="Cqz"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="深度学习"><meta name="twitter:description" content="深度学习"><meta name="twitter:image" content="https://mega-cqz.github.io/img/Fate.jpg"><meta property="og:type" content="article"><meta property="og:title" content="深度学习"><meta property="og:url" content="https://mega-cqz.github.io/2020/02/28/DLLearn/"><meta property="og:site_name" content="世界で一番おひめさま"><meta property="og:description" content="深度学习"><meta property="og:image" content="https://mega-cqz.github.io/img/Fate.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://mega-cqz.github.io/2020/02/28/DLLearn/"><link rel="prev" title="Redis" href="https://mega-cqz.github.io/2020/03/01/Redis/"><link rel="next" title="机器学习" href="https://mega-cqz.github.io/2020/02/28/mlLearn/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">世界で一番おひめさま</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 清单</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/%E9%BB%84%E6%BC%AB%E8%80%81%E5%B8%88.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">9</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">9</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 清单</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#CNN"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">CNN</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#LSTM"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">LSTM</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#GPU加速原理"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">GPU加速原理</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#梯度下降"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">梯度下降</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#杂烩"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text">杂烩</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Adam"><span class="toc_mobile_items-number">4.2.</span> <span class="toc_mobile_items-text">Adam</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#选择"><span class="toc_mobile_items-number">4.3.</span> <span class="toc_mobile_items-text">选择</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#FTRL"><span class="toc_mobile_items-number">4.4.</span> <span class="toc_mobile_items-text">FTRL</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#word2vec"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">word2vec</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Attention"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">Attention</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Droupout"><span class="toc_mobile_items-number">7.</span> <span class="toc_mobile_items-text">Droupout</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#BN原理"><span class="toc_mobile_items-number">8.</span> <span class="toc_mobile_items-text">BN原理</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#面试"><span class="toc_mobile_items-number">8.0.1.</span> <span class="toc_mobile_items-text">面试</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Embedding"><span class="toc_mobile_items-number">9.</span> <span class="toc_mobile_items-text">Embedding</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#FocalLoss"><span class="toc_mobile_items-number">10.</span> <span class="toc_mobile_items-text">FocalLoss</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#ResNet"><span class="toc_mobile_items-number">11.</span> <span class="toc_mobile_items-text">ResNet</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#归一化"><span class="toc_mobile_items-number">12.</span> <span class="toc_mobile_items-text">归一化</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#数据不平衡"><span class="toc_mobile_items-number">13.</span> <span class="toc_mobile_items-text">数据不平衡</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#蓄水池算法"><span class="toc_mobile_items-number">14.</span> <span class="toc_mobile_items-text">蓄水池算法</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#CNN"><span class="toc-number">1.</span> <span class="toc-text">CNN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#LSTM"><span class="toc-number">2.</span> <span class="toc-text">LSTM</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GPU加速原理"><span class="toc-number">3.</span> <span class="toc-text">GPU加速原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#梯度下降"><span class="toc-number">4.</span> <span class="toc-text">梯度下降</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#杂烩"><span class="toc-number">4.1.</span> <span class="toc-text">杂烩</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adam"><span class="toc-number">4.2.</span> <span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#选择"><span class="toc-number">4.3.</span> <span class="toc-text">选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FTRL"><span class="toc-number">4.4.</span> <span class="toc-text">FTRL</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#word2vec"><span class="toc-number">5.</span> <span class="toc-text">word2vec</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Attention"><span class="toc-number">6.</span> <span class="toc-text">Attention</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Droupout"><span class="toc-number">7.</span> <span class="toc-text">Droupout</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#BN原理"><span class="toc-number">8.</span> <span class="toc-text">BN原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#面试"><span class="toc-number">8.0.1.</span> <span class="toc-text">面试</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Embedding"><span class="toc-number">9.</span> <span class="toc-text">Embedding</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#FocalLoss"><span class="toc-number">10.</span> <span class="toc-text">FocalLoss</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ResNet"><span class="toc-number">11.</span> <span class="toc-text">ResNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#归一化"><span class="toc-number">12.</span> <span class="toc-text">归一化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#数据不平衡"><span class="toc-number">13.</span> <span class="toc-text">数据不平衡</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#蓄水池算法"><span class="toc-number">14.</span> <span class="toc-text">蓄水池算法</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(/img/Fate.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">深度学习</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-02-28<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-03-02</time><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p>卷积：对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重）做内积操作。<br>卷积的重要的物理意义是：一个函数（如：单位响应）在另一个函数（如：输入信号）上的加权叠加。<br>卷积神经网络CNN是多层感知机(MLP)的变种。20世纪60年代，Hubel等在研究猫脑皮层时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了CNN。 </p>
<p>CNN：局部连接和共享权值的方式，减少了的权值的数量使得网络易于优化，另一方面降低了过拟合的风险。该优点在网络的输入是多维图像时表现的更为明显，使图像可以直接作为网络的输入，避免了传统识别算法中复杂的特征提取和数据重建过程。在二维图像处理上有众多优势。<br>CNN具有一些传统技术所没有的优点：良好的容错能力、并行处理能力和自学习能力，可处理环境信息复杂，背景知识不清楚，推理规则不明确情况下的问题，允许样品有较大的缺损、畸变，运行速度快，自适应性能好，具有较高的分辨率。它是通过结构重组和减少权值将特征抽取功能融合进多层感知器，省略识别前复杂的图像特征抽取过程。<br>CNN的泛化能力要显著优于其它方法，卷积神经网络已被应用于模式分类，物体检测和物体识别等方面。利用卷积神经网络建立模式分类器，将卷积神经网络作为通用的模式分类器，直接用于灰度图像。<br>）</p>
<p>1×1的卷积大概有两个方面的作用吧：</p>
<ol>
<li>实现跨通道的交互和信息整合<br>例子：使用1*1卷积核，实现降维和升维的操作其实就是channel间信息的线性组合变化，3 3，64channels的卷积核后面添加一个1*1，28channels的卷积核，就变成了3*3，28channels的卷积核，原来的64个channels就可以理解为跨通道线性组合变成了28channels，这就是通道间的信息交互。<br>注意：只是在channel维度上做线性组合，W和H上是共享权值的sliding window</li>
<li>进行卷积核通道数的降维和升维<br>上一个例子中，不仅在输入处有一个1*1卷积核，在输出处也有一个卷积核，3*3，64的卷积核的channel是64，只需添加一个1*1，256的卷积核，只用64*256个参数就能把网络channel从64拓宽四倍到256。</li>
<li>实现全连接<br>卷积层就相当于一个卷积核，对于传送过来的feature map进行局部窗口滑动，无论你输入的feature map多大(不能小于卷积核的大小)，都不会对卷积造成影响，而全连接使用的是图像的全局信息。<br>全连接层的坏处就在于其会破坏图像的空间结构，因此人们便开始用卷积层来“代替”全连接层，通常采用1×1的卷积核，这种不包含全连接的CNN成为全卷积神经网络（Fully Convolutional Networks, FCN），FCN最初是用于图像分割任务，之后开始在计算机视觉领域的各种问题上得到应用，事实上，Faster R-CNN中用来生成候选窗口的CNN就是一个FCN。FCN的特点就在于输入和输出都是二维的图像，并且输入和输出具有相对应的空间结构，在这种情况下，我们可以将FCN的输出看作是一张热度图，用热度来指示待检测的目标的位置和覆盖的区域。在目标所处的区域内显示较高的热度，而在背景区域显示较低的热度，这也可以看成是对图像上的每一个像素点都进行了分类，这个点是否位于待检测的目标上。<br>4增加非线性<br>1*1卷积核，可以在保持feature map尺度不变的（即不损失分辨率）的前提下大幅增加非线性特性（利用后接的非线性激活函数），把网络做的很deep。<br>备注：一个filter对应卷积后得到一个feature map，不同的filter(不同的weight和bias)，卷积以后得到不同的feature map，提取不同的特征，得到对应的specialized neuro。</li>
</ol>
<p>输入图片大小：W x W<br>Filter大小：F x F       Stride：S        Padding ：P        输出图片：N x N<br>N = ( W - F + 2*P )/S + 1    卷积向下取整，池化层向上取整<br>假设一个卷积层：输入224×224×3，输出224×224×64，卷积核大小为3×3。<br>计算量： Times = 224 × 224 × 3 × 3 × 3 × 64 = 8.7 × 10^7<br>参数量： Space = 3 × 3 × 3 × 64 = 1728<br>首先，您可以使用几个较小的核而不是几个较大的核来获得相同的感受野并捕获更多的空间上下文，但是使用较小的内核时，您使用的参数和计算量较少。<br>其次，因为使用更小的核，您将使用更多的滤波器，您将能够使用更多的激活函数，从而使您的CNN学习到更具区分性的映射函数。</p>
<p>优化计算：<br>采用快速傅里叶变换fft/fft convolution<br>  优点：该种方法效率非常高<br>  缺点：由于filter需要扩大到和input一样大小，占用了大量内存，特别是CNN的前几层filter 大小远小于input大小。而且，当striding 参数>1, fft效率也不高。<br>  此时需要将卷积核扩大成和feature map一样的长宽尺寸，这在二者相差较大的时候也是很浪费的。另外，当stride大于1时，数据比较稀疏，采用FFT效果也并不理想。<br>  这是一种加速的2d卷积，matlab中有。 该种方法效率非常高，但是由于filter需要扩大到和input一样大小，占用了大量内存，特别是CNN的前几层filter 大小远小于input大小。第二，当striding 参数>1, fft效率也不高。<br>实际效果<br>  对于大矩阵，filter2或conv2太慢了，而使用convfft有极大的提速（100 ^ 2和500^2的矩阵进行卷积时，加速为5-10倍。<br>cuDNN convolution<br>  论文采用的是将卷积转化为矩阵乘法的方法，利用NVIDIA的矩阵乘法的特点，做了一些改进。<br>  具体来说就是，计算F（卷积核）对D（输入的feature map）的卷积，并不是将D转化后的二维矩阵直接存到显存里面，而是lazily materialing的方式。就是说，当需要用到这部分数据的时候，直接到D中索引对应的数据，并加载到显存里面进行计算，这样就避免了占用额外显存这一弊端。<br>  因此该方法还需要一个快速从D中索引数据的算法。<br>  对A x B = C, 分块加载A和B从off-chip memory to on-chip caches, 同时计算C的一部分。这样减少了数据传输带来的延迟。对于扩大的input data，我们是在on-chip上转换成扩大的input data，而不是在off-chip上转换。<br>在这里插入图片描述<br>caffe中实现的方法（NVIDIA的矩阵乘法）<br>  将卷积操作转换为密集矩阵相乘。将input data组装成大小为CRS x NPQ的矩阵，这使得内存相对原始input data的大小扩大了之多RS（即kernel_size的平方）倍。<br>  这种方法使用扩大临时内存方法换取密集矩阵计算的便利。<br>  卷积核越大，stride越小，显存耗费越高。</p>
<p>卷积核一般都把size设为奇数，主要有以下两个原因：<br>1.保证了锚点（卷积核的中心）刚好在中间，方便以模块中心为标准进行滑动卷积。<br>2.保证了padding时，图像的两边依然相对称。<br>奇数相对于偶数，有中心点，对边沿、对线条更加敏感，可以更有效的提取边沿信息。<br>偶数也可以使用，但是效率比奇数低。在数以万计或亿计的计算过程中，每个卷积核差一点，累计的效率就会差很多<br>•    保护位置信息：保证了 锚点 刚好在中间，方便以模块中心为标准进行滑动卷积，避免了位置信息发生 偏移 。<br>•    padding时对称：保证了 padding 时，图像的两边依然相 对称 。<br>在卷积时，我们有时候需要卷积前后的尺寸不变。这时候我们就需要用到padding。假设图像的大小，也就是被卷积对象的大小为n*n，卷积核大小为k*k，padding的幅度设为(k-1)/2时，卷积后的输出就为(n-k+2<em>((k-1)/2))/1+1=n，即卷积输出为n\</em>n，保证了卷积前后尺寸不变。但是如果k是偶数的话，(k-1)/2就不是整数了。在CNN中，进行卷积操作时一般会以卷积核模块的一个位置为基准进行滑动，这个基准通常就是卷积核模块的中心。若卷积核为奇数，卷积锚点很好找，自然就是卷积模块中心，但如果卷积核是偶数，这时候就没有办法确定了，让谁是锚点似乎都不怎么好。</p>
<h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130817078.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130817078.png" class="lazyload" title="enter description here"></a></p>
<h1 id="GPU加速原理"><a href="#GPU加速原理" class="headerlink" title="GPU加速原理"></a>GPU加速原理</h1><p>对于GPU来说，它的任务是在屏幕上合成显示数百万个像素的图像——也就是同时拥有几百万个任务需要并行处理，因此GPU被设计成可并行处理很多任务，而不是像CPU那样完成单任务。<br>因此CPU和GPU架构差异很大，CPU功能模块很多，能适应复杂运算环境；GPU构成则相对简单，目前流处理器和显存控制器占据了绝大部分晶体管。CPU中大部分晶体管主要用于构建控制电路（比如分支预测等）和Cache，只有少部分的晶体管来完成实际的运算工作。而GPU的控制相对简单，且对Cache的需求小，所以大部分晶体管可以组成各类专用电路、多条流水线，使得GPU的计算速度有了突破性的飞跃，拥有了更强大的处理浮点运算的能力。<br>GPU特别擅长处理矩阵（这是CPU无法应对的问题），而且这也适用于深度学习等专业应用程序。此外，与CPU相比，可以将更多的专用GPU核心塞入处理器芯片中。例如，对于Intel xeon（Xeon是英特尔公司的一款处理器）来说，目前你可能希望每个插槽最多可以容纳28个核心，而GPU允许容纳数千个核心，而且可以同时处理AI数据。因为深度学习在训练的时候要更新很多很多很多参数，用cpu太费时间，用gpu可以并行处理的运算比cpu多的多CPU更擅长于快速获取少量的内存（5*3*7），GPU则更擅长于获取大量的内存（矩阵乘法：（A*B）*C）。<br>另一方面，最好的CPU大约能达到50GB/s的内存带宽，而最好的GPU能达到750GB/s的内存带宽。因此，在内存方面，计算操作越复杂，GPU对CPU的优势就越明显。<br>CPU是一个有多种功能的优秀领导者。它的优点在于调度、管理、协调能力强，计算能力则位于其次。而GPU相当于一个接受CPU调度的“拥有大量计算能力”的员工。<br>CPU擅长统领全局等复杂操作，GPU擅长对大数据进行简单重复操作。CPU是从事复杂脑力劳动的教援，而GPU是进行大量并行计算的体力劳动者。<br>GPU具有如下特点：<br>1 、提供了多核并行计算的基础结构，且核心数非常多，可以支撑大量数据的并行计算。<br>并行计算或称平行计算是相对于串行计算来说的。它是一种一次可执行多个指令的算法，目的是提高计算速度，及通过扩大问题求解规模，解决大型而复杂的计算问题。<br>2、 拥有更高的访存速度。<br>3、更高的浮点运算能力。浮点运算能力是关系到处理器的多媒体、3D图形处理的一个重要指标。现在的计算机技术中，由于大量多媒体技术的应用，浮点数的计算大大增加了，比如3D图形的渲染等工作，因此浮点运算的能力是考察处理器计算能力的重要指标。<br>这三个特点，非常适合深度学习了。<br>除了计算核心的增加，GPU另一个比较重要的优势就是他的内存结构。首先是共享内存。在NVIDIA披露的性能参数中，每个流处理器集群末端设有共享内存。相比于CPU每次操作数据都要返回内存再进行调用，GPU线程之间的数据通讯不需要访问全局内存，而在共享内存中就可以直接访问。这种设置的带来最大的好处就是线程间通讯速度的提高（速度：共享内存》全局内存）。<br>再就是高速的全局内存（显存）：目前GPU上普遍采用GDDR5的显存颗粒不仅具有更高的工作频率从而带来更快的数据读取/写入速度，而且具有更大的显存带宽。我们认为在数据处理中，速度往往最终取决于处理器从内存中提取数据以及流入和通过处理器要花多少时间。</p>
<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><h2 id="杂烩"><a href="#杂烩" class="headerlink" title="杂烩"></a>杂烩</h2><p>神经网络的主要任务是在学习时找到最优的参数（权重和偏置），这个最优参数也就是损失函数最小时的参数。但是，一般情况下，损失函数比较复杂，参数也很多，无法确定在哪里取得最小值。所以通过梯度来寻找最小值（或者尽可能小的值）的方法就是梯度法。<br>   需要注意的是，梯度表示的是各点处的函数值减少最多的方向，所以梯度的方向并不一定指向最小值。但是沿着它的方向能够最大限度地减少函数的值。因此，在寻找函数的最小值（或者尽可能小的值）的位置的时候，要以梯度的信息为线索，决定前进的方向。<br>   此时梯度法就派上用场了。在梯度法中，函数的取值从当前位置沿着梯度方向前进一定距离，然后在新的方向重新求梯度，再沿着新梯度方向前进，如此反复。<br>   像这样，通过不断地沿梯度方向前进，逐渐减小函数值的过程就是梯度法（gradient mothod）。一般来说，神经网络（深度学习）中，梯度法主要是指梯度下降法（gradient descent mothod）。<br>一、梯度下降的变种算法<br>1、BGD<br>批量梯度下降法更新一次参数需要计算整个数据集所有样本的梯度，因此更新速度非常慢，对于凸优化问题会收敛到全局最优点、而非凸优化问题则会收敛到局部最优点，这种方法有可能无法将大量的数据放入内存，也不能进行在线学习。<br>2、SGD<br>随机梯度下降法更新一次参数只需计算一个样本的梯度，（只通过一个随机选取的数据(xn,yn) 来获取“梯度）更新速度很快、参数方差波动大，适用于在线学习，有可能跳出局部最优到达全局最优。训练时每个epoch结束后注意必须要shuffle训练集：<br>SGD是在线学习最基本的模式，因为SGD训练得到的特征不具有稀疏性，从工程的角度来说占用内存过大。L1-norm在在线学习中效果不佳，因为梯度的方向不是全局的方向，而是沿着样本的梯度方向，会造成每次没有被充分训练的样本错误地将系数归零。<br>3、MBGD<br>小批量梯度下降法既减少了SGD参数方差的波动性，又可以利用深度学习库中高度优化的矩阵运算的便捷性，一般mini-batch size在50到256之间，每次参数更新计算小批量样本的梯度，也需要在每个epoch后shuffle数据集。<br>Shuffle：给定权重取值w1、w2和迭代步step的情况下，固定的数据集顺序意味着固定的训练样本，也就意味着权值更新的方向是固定的，而无顺序的数据集，意味着更新方向是随机的。<br>以上3种方法的challenges在于：<br>（1）选择合适的学习率比较困难，如果学习率过小，则J很长时间才能收敛；学习率过大，则J会震荡甚至发散。<br>（2）可以通过诸如退火annealing，即根据预先确定的学习率或当两次epoch间发生的变化低于一个阈值时，降低学习率的值。这些规划和阈值必须提前定义，因此无法动态适应数据集的特征。<br>（3）由于所有参数的更新使用相同的学习率，对于稀疏数据且出现频率差别非常大的特征，我们可能不想让它们更新相同的程度，如对于很少出现的特征进行较大的更新、对经常出现的特征进行较小的更新，这样以上的方法都不能满足要求。<br>（4）容易困在鞍点（SGD尤甚，因为鞍点处所有维度梯度趋近于0），只收敛到局部最优点。<br>二、梯度下降的优化算法<br>1、Momentum<br>Momentum是模拟物理学动量的概念，累积之前的动量加入梯度，能够在相关方向加速SGD，抑制震荡，从而加快收敛速度：<br>通过加入衰减分量γ更新向量v，一般γ=0.9或其他类似的值，令早期的梯度对当前的梯度影响越来越小，如果没有衰减值，模型往往会震荡、难以收敛，甚至发散。<br>此方法可以理解为小球从山顶落向山谷，因动量的累积使得速度越来越快，由于空气阻力的存在γ<1。同样地，在参数更新时：与梯度方向相同的维度动量增加、在梯度改变方向的维度动量减少，这样就能得到更快的收敛和减少振荡。<br>2、Nesterov accelerated gradient（NAG）<br>这一次的小球变得更加聪明，不会盲目地沿着坡滚动，例如在山坡快要上升的时候知道需要减速。NAG是赋予动量项这种“先见之明”的方法，使用 \theta -\gamma v_{t-1} 近似地作为参数下一步的值，这样在计算梯度时，就不是在当前位置，而是在未来的位置上进行：<br>Momentum过程首先计算当前梯度（短的蓝色向量），然后在更新后的累积梯度的方向进行一个大的跳跃（长的蓝色向量）；NAG首先在之前累积的梯度方向进行一个大的跳跃（棕色向量），然后衡量梯度进行修正校正（绿色向量）。这种预期的更新避免了更新速度过快、提高了结果的响应性，并极大地提高了RNN在许多任务上的性能。<br>NAG与Momentum的区别是，梯度计算不同，NAG先用当前的速度v更新一遍参数，再用更新的临时参数计算梯度，相当于添加了二阶校正因子的Momentum。这两种方法可以在更新梯度时顺应J的梯度来调整速度，并且对SGD进行加速。除此之外我们还希望可以根据参数的重要性而对不同的参数进行不同程度的更新。<br>3、适应性梯度算法Adagrad<br>在传统机器学习中，一种加速迭代的方法就是将数值归一化到一个以原点为中心的空间内。Adagrad通过累积梯度约束学习率，提升SGD的robustness，并且能让不频繁出现的参数进行较大的更新、频繁出现的参数进行较小的更新，尤其适用于稀疏数据的情况。由于每一步每个参数的学习率都不相同，令 g_{t,i} 为t时刻第i个参数 \theta {i} 的目标函数的梯度：<br>对于SGD，参数 \theta {i} 在每一时刻的梯度更新公式为：<br>令 G_{t} 为对角矩阵，表示前t步参数 \theta {i} 梯度的累加，矩阵对角线上的元素(i,i)是t时刻参数 \theta {i} 的梯度平方和；ϵ为平滑项（类似1e-8之类极小的数）避免分母为0，则Adagrad的参数更新公式为：<br>Adagrad的优点在于不需要对学习率进行手动调节，一般default为0.01后就不用管了，让它在学习的过程中自己变化。缺点在于分母中G累积了平方梯度后不断增大，这导致了学习率逐渐衰减为一个很小的数，尽管真实情况是参数的更新随着梯度增大而增大，但是到了后期由于分母越来越大，网络不再能够学到更多的知识，训练将提前结束。<br>4、Adadelta<br>Adadelta的基本思想是用一阶的方法近似模拟二阶牛顿法，是Adagrad的扩展，仍然是对学习率进行自适应约束，但进行了计算上的简化，只递归累加之前固定数量w个的梯度平方之和，并且也不直接存储这些项，仅近似计算对应的平均值。Adadelta将Adagrad公式中的对角矩阵G替换为 E[g^{2}]<em>{t} ，E[g^{2}]</em>{t} 表示t时刻之前w个梯度平方的动态衰减平均值：<br>其中γ为类似动量项的超参，在0.9左右。这个分母相当于梯度的均方根误差root mean squared error（RMSE）。为了使更新有与参数相同的假设单元，定义一个指数衰减平均值，这次不是梯度平方 g^{2} 而是参数平方的更新\Delta<br>此时参数的更新仍然依赖全局学习率。经过近似牛顿法将学习率η替换为 \mathrm{RMSE}[\Delta \theta ]{t-1} 之后：<br>Adadelta就不依赖于全局学习率η了。这种方法在训练初、中期，加速效果很好；但到了训练后期，会反复在局部最小值附近抖动，主要体现在验证集错误率上，摆脱不了局部极小值吸引盆。此时切换为动量SGD，并将学习率降低一个量级，就可以使验证集正确率有2%~5%的提升。<br>Adadelta算法流程：<br>5、均方根传播RMSprop<br>RMSprop是Hinton在Coursera公开课上提出的一种自适应学习率方法，和Adadelta一样都是为了解决Adagrad学习率急剧下降的问题。RMSprop同样使用指数加权平均来消除梯度下降中摆动，但仍依赖于全局学习率η，效果介于Adagrad和Adadelta之间。<br>超参数设置建议为γ=0.9，η=0.001。这种方法适用于非稳态non-stationary和在线问题，对RNN效果很好。<br>6、Adaptive Moment Estimation<br>带动量的：Momentum，NAG动量主要解决SGD的两个问题：一是随机梯度的方法（引入的噪声）；二是Hessian矩阵病态问题（可以理解为SGD在收敛过程中和正确梯度相比来回摆动比较大的问题）。<br>　　　　理解策略为：由于当前权值的改变会受到上一次权值改变的影响，类似于小球向下滚动的时候带上了惯性。这样可以加快小球向下滚动的速度<br>自适应的：adagrad，adadelta，RMSprop（适合数据稀疏的）<br>独立地适应所有模型参数的学习率，缩放每个参数反比于其所有梯度历史平均值总和的平方根<br>　　　　　　具有代价函数最大梯度的参数相应地有个快速下降的学习率，而具有小梯度的参数在学习率上有相对较小的下降。</p>
<p>关于牛顿法和梯度下降法的效率对比：<br>　　从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）<br>　　根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p>•    简单直接的实施<br>•    计算上讲究效率<br>•    小内存要求<br>•    不变量对梯度的对角线重新调节<br>•    非常适合于数据和/或参数方面的问题<br>•    适合非平稳的目标<br>•    适用于非常稀梳梯度的问题。<br>•    超参数具有直观的解释，通常需要很少的调谐。<br>Vt二阶矩==动量<br>Momentum通过对梯度mean的估计，使得梯度在纵向上的正负步长逐步抵消，横向上的步长逐步累积，从而减少了震荡，加快了学习速率。<br>可以认为：对于mean的这种估计，其实是从噪音中提取到了有效信号，因为信号的方向在一段时间内是不会变的。同时抵消了噪音，比如白噪音，它的均值为0，把多个白噪音累加后，它们是正负相互抵消的<br>Adam中的vt。它的思路是这样的，对于波动比较大的梯度，它的方差肯定是很大的，所以它用梯度去除以二阶距的开方，作为梯度下降的梯度，从而也使得它在纵轴上的步长减小了，同时相对的增加了横轴的步长。<br>这个也是mt和vt的设计来源。同时因为mt和vt涉及了所有历史梯度信息，所以他们都能较好处理梯度稀疏的情况。<br>随机梯度下降保持一个单一的学习速率(称为alpha)，用于所有的权重更新，并且在训练过程中学习速率不会改变。每一个网络权重(参数)都保持一个学习速率，并随着学习的展开而单独地进行调整。该方法从梯度的第一次和第二次矩的预算来计算不同参数的自适应学习速率。<br>•    alpha也被称为学习速率或步长。权重比例被校正(例如001)。更大的值(例如0.3)在速率校正之前会加快初始学习速度。较小的值(例如1.0e-5)在培训期间降低学习速度<br>•    beta1。第一次估计的指数衰减率(如9)。<br>•    beta2。第二次估计的指数衰次减率(例如999)。在稀疏梯度问题(例如NLP和计算机视觉问题)上，这个值应该接近1.0。<br>•    epsilon是一个非常小的数字，可以防止任何在实施中被0划分(例如，10e-8)。<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131122919.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131122919.png" class="lazyload" title="enter description here"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131135273.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131135273.png" class="lazyload" title="enter description here"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131160728.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131160728.png" class="lazyload" title="enter description here"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131171772.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131171772.png" class="lazyload" title="enter description here"></a><br>根据我们在Momentum和RMSProp中的描述，m/sqrt(v)可以看做是对梯度“信噪比”（SNR）的估计，其中m是信号量，而v是噪音量。当噪音大时，步长小；噪音小时，步长大。这正是我们需要的特性，从而使得Adam能够较好的处理噪音样本，另外，当我们接近最优点时，噪音通常会变得很大，或者说真正的信号变得很微弱，信噪比通常会接近0，这样步长就会变得较小，从而天然起到退火效果(annealing)</p>
<h2 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h2><p>（1）对于稀疏数据，尽量使用学习率可以自适应的优化方法，不需要手动调节η；<br>（2）RMSprop是Adagrad的扩展，解决了Adagrad学习率迅速下降的问题；与Adadelta类似，后者使用RMS的参数更新方法；Adam是添加了偏置校正和动量项的RMSprop。Adagrad，Adadelta，RMSprop，Adam都是比较相近的算法，在相似的情况下表现良好。Adam在优化后期梯度变得稀疏时效果比RMSprop稍好一些，因此推荐使用Adam算法；<br>（3）一般在想要使用带动量项的RMSprop或Adam时，大多数都可以使用Nadam取得更好的效果。<br>（4）SGD通常训练时间很长，容易陷入鞍点，但是在采取robust的初始化、退火规划annealing schedule、data shuffling和early stopping等合理措施的情况下，结果更加可靠；<br>（5）如果需要更快的收敛，且需要训练较深较为复杂的网络时，推荐使用学习率自适应的优化方法；</p>
<h2 id="FTRL"><a href="#FTRL" class="headerlink" title="FTRL"></a>FTRL</h2><p>Follow-The-Regularized-Leader是Google经过三年时间（2010-2013）从理论研究到实际工程化的一种在线学习算法，在处理诸如逻辑回归之类的带非光滑正则项（L1-norm）的凸优化问题的性能非常出色。在线学习不需要cache所有的数据，以流式处理方式就可以处理任意数量的样本，分为在线凸优化和在线Bayesian两种：<br>在线凸优化的方法有很多，如Truncated Gradient、FOBOS、RDA（Regularized Dual Averaging）、FTRL等；<br>在线Bayesian方法有AdPredictor算法、基于内容的在线矩阵分解算法等。<br>FTRL是一种适合处理超大规模数据的、含大量稀疏特征的在线学习常见的优化算法，常用于更新在线的CTR预估模型；结合了FOBOS精度较高和RDA稀疏性好的优势，在L1范数或其他非光滑的正则项下，FTRL比前两者更加有效。<br>(FOBOS-L1：使用MSE+L1对w_{t+1/2}进行建模，目标是使调整后的梯度在离SGD结果附近的基础上，产出稀疏解；<br>RDA-L1：使用累积平均梯度 + L1 + L2进行建模，这里使用L2有两方面的理解：<br>能产出极小值点；<br>调整后的梯度不能与零点太远；<br>从loss function的形式来看：FTRL就是将RDA-L1的“梯度累加”思想应用在FOBOS-L1上，并施加一个L2正则项。<br>这样达到的效果是： 累积加和限定了新的迭代结果W不要离“已迭代过的解”太远**；<br>因为调整后的解不会离迭代过的解太远，所以保证了每次找到让之前所有损失函数之和最小的参数；<br>保留的RDA-L1中关于累积梯度的项，可以看作是当前特征对损失函数的贡献的一个估计【累积梯度越大，贡献越大。】<br>由于使用了累积梯度，即使某一次迭代使某个重要特征约束为0，但如果后面这个特征慢慢变得稠密，它的参数又会变为非0；<br>保留的RDA-L1中关于累积梯度的项，与v相加，总会比原来的v大，加起来的绝对值更容易大于L1的阈值，保护了重要的特征；<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131238225.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131238225.png" class="lazyload" title="enter description here"></a><br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131225599.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131225599.png" class="lazyload" title="enter description here"></a></p>
<h1 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h1><p>word2vec模型其实就是简单化的神经网络。<br>输入是One-Hot Vector，Hidden Layer没有激活函数，也就是线性的单元。Output Layer维度跟Input Layer的维度一样，用的是Softmax回归。我们要获取的dense vector其实就是Hidden Layer的输出单元。有的地方定为Input Layer和Hidden Layer之间的权重，其实说的是一回事。<br>CBOW与Skip-Gram模式<br>word2vec主要分为CBOW（Continuous Bag of Words）和Skip-Gram两种模式。CBOW是从原始语句推测目标字词；而Skip-Gram正好相反，是从目标字词推测出原始语句。CBOW对小型数据库比较合适，而Skip-Gram在大型语料中表现更好。<br>两种优化算法：层次Softmax（Hierarchical Softmax）哈夫曼树和负采样（Negative Sampling）。<br>美团推荐：协同过滤，location-based，query-based，graph-based，实时用户行为，替补策略</p>
<h1 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h1><p>Attention分为空间注意力和时间注意力，前者用于图像处理，后者用于自然语言处理<br>Attention的原理就是计算当前输入序列与输出向量的匹配程度，匹配度高也就是注意力集中点其相对的得分越高，其中Attention计算得到的匹配度权重，只限于当前序列对，不是像网络模型权重这样的整体权重。Attention的原理就是计算当前输入序列与输出向量的匹配程度，匹配度高也就是注意力集中点其相对的得分越高，其中Attention计算得到的匹配度权重，只限于当前序列对，不是像网络模型权重这样的整体权重。<br>在编解码器框架内，通过在编码段加入Attention模型，对源数据序列进行数据加权变换，或者在解码端引入Attention 模型，对目标数据进行加权变化，可以有效提高序列对序列的自然方式下的系统表现。<br>可以看到，Decoder分别接收了不一样的输入C1 C_1C ，输出不同词，加入不同的c，使输出更贴近理想值<br>Attention机制的基本思想是：打破了传统编码器-解码器结构在编解码时都依赖于内部一个固定长度向量的限制。<br>Attention机制的实现是 通过保留LSTM编码器对输入序列的中间输出结果，然后训练一个模型来对这些输入进行选择性的学习并且在模型输出时将输出序列与之进行关联。<br>换一个角度而言，输出序列中的每一项的生成概率取决于在输入序列中选择了哪些项。<br>Attention-based Model 其实就是一个相似性的度量，当前的输入与目标状态约相似，那么在当前的输入的权重就会越大。就是在原有的model上加入了Attention的思想。<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131265846.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131265846.png" class="lazyload" title="enter description here"></a><br>match模块可以看作是在计算e ee和z zz的相似度，如上图右边所示。z zz是Decoder模块的隐含层变量，<br> 是隐含层的初始值。match模块常有三种选择：1）直接计算向量的余弦相似度；2）一个小的神经网络模型，输入是e ee和z zz，输出是一个标量；3）矩阵分解<br>soft / global / dynamic (都是soft attention)<br>是求概率分布，就是对于任意一个单词或者values都给出概率，attention得分经过softmax后权值用aph表示，把attention向量用ct表示。<br>hard attention<br>一般用在图像中 只选中一个区域，只选1个，其余为0。<br>local attention(半软半硬attention)<br>先选中一个区域，然后在其中的各个小部分生成概率分布。<br>静态attention<br>对输出句子共用一个St。一般在BiLstm首位hidden state输出拼接起来作为St(图中为u)。<br>Self- attention<br>在没有额外信息下，仍然可以允许向量values使用self attention来处理自己，从句子中提取需要关注的信息。<br>key-values attention<br>即将hi 隐藏状态拆分成两部分一部分是key(i) 一部分是values(i)然后只针对key部分计算attention的权值，然后加权使用values部分的值进行加权求和。</p>
<h1 id="Droupout"><a href="#Droupout" class="headerlink" title="Droupout"></a>Droupout</h1><p>取平均的作用： 先回到标准的模型即没有dropout，我们用相同的训练数据去训练5个不同的神经网络，一般会得到5个不同的结果，此时我们可以采用 “5个结果取均值”或者“多数取胜的投票策略”去决定最终结果。例如3个网络判断结果为数字9,那么很有可能真正的结果就是数字9，其它两个网络给出了错误结果。这种“综合起来取平均”的策略通常可以有效防止过拟合问题。因为不同的网络可能产生不同的过拟合，取平均则有可能让一些“相反的”拟合互相抵消。dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。<br>（2）减少神经元之间复杂的共适应关系： 因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 。迫使网络去学习更加鲁棒的特征 ，这些特征在其它的神经元的随机子集中也存在。换句话说假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的特征。从这个角度看dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高。<br>（3）Dropout类似于性别在生物进化中的角色：物种为了生存往往会倾向于适应这种环境，环境突变则会导致物种难以做出及时反应，性别的出现可以繁衍出适应新环境的变种，有效的阻止过拟合，即避免环境改变时物种可能面临的灭绝。</p>
<h1 id="BN原理"><a href="#BN原理" class="headerlink" title="BN原理"></a>BN原理</h1><p>解决梯度消失<br>训练深度网络时，神经网络隐层参数更新会导致网络输出层输出数据的分布发生变化，而且随着层数的增加，根据链式规则，这种偏移现象会逐渐被放大。这对于网络参数学习来说是个问题：因为神经网络本质学习的就是数据分布（representation learning），如果数据分布变化了，神经网络又不得不学习新的分布。为保证网络参数训练的稳定性和收敛性，往往需要选择比较小的学习速率（learning rate），同时参数初始化的好坏也明显影响训练出的模型精度，特别是在训练具有饱和非线性（死区特性）的网络，比如即采用S或双S激活函数网络，比如LSTM，GRU。<br>解决办法：引入Batch Normalization，作为深度网络模型的一个层，每次先对input数据进行归一化，再送入神经网络输入层。</p>
<p>因为初始的W是从标准高斯分布中采样得到的，而W中元素的数量远大于x，Wx+b每维的均值本身就接近0、方差接近1，所以在Wx+b后使用Batch Normalization能得到更稳定的结果。每一维度减去自身均值，再除以自身标准差，由于使用的是随机梯度下降法，这些均值和方差也只能在当前迭代的batch中计算，故作者给这个算法命名为Batch Normalization。这里有一点需要注意，像卷积层这样具有权值共享的层，Wx+b的均值和方差是对整张map求得的，在batch_size * channel * height * width这么大的一层中，对总共batch_size*height*width个像素点统计得到一个均值和一个标准差，共得到channel组参数。<br>因为可能由于这种的强制转化导致数据的分布发生破话。因此需要对公式的鲁棒性进行优化，就有人提出了变换重构的概念。就是在基础公式的基础之上加上了两个参数γ、β。这样在训练过程中就可以学习这两个参数，采用适合自己网络的BN公式。公式如下：<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131300976.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131300976.png" class="lazyload" title="enter description here"></a><br>每一个神经元都会有一对这样的参数γ、β。这样其实当：<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131313595.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131313595.png" class="lazyload" title="enter description here"></a><br>时，是可以恢复出原始的某一层所学到的特征的。引入可学习重构参数γ、β，让网络可以学习恢复出原始网络所要学习的特征分布。<br> (1) 可以使用更高的学习率。如果每层的scale不一致，实际上每层需要的学习率是不一样的，同一层不同维度的scale往往也需要不同大小的学习率，通常需要使用最小的那个学习率才能保证损失函数有效下降，Batch Normalization将每层、每维的scale保持一致，那么我们就可以直接使用较高的学习率进行优化。<br>　　(2) 移除或使用较低的dropout。 dropout是常用的防止overfitting的方法，而导致overfit的位置往往在数据边界处，如果初始化权重就已经落在数据内部，overfit现象就可以得到一定的缓解。论文中最后的模型分别使用10%、5%和0%的dropout训练模型，与之前的40%-50%相比，可以大大提高训练速度。<br>　　(3) 降低L2权重衰减系数。 还是一样的问题，边界处的局部最优往往有几维的权重（斜率）较大，使用L2衰减可以缓解这一问题，现在用了Batch Normalization，就可以把这个值降低了，论文中降低为原来的5倍。<br>　　(4) 取消Local Response Normalization层。 由于使用了一种Normalization，再使用LRN就显得没那么必要了。而且LRN实际上也没那么work。<br>(5) 减少图像扭曲的使用。 由于现在训练epoch数降低，所以要对输入数据少做一些扭曲，让神经网络多看看真实的数据。</p>
<p>BN和Dropout单独使用都能减少过拟合并加速训练速度，但如果一起使用的话并不会产生1+1>2的效果，相反可能会得到比单独使用更差的效果。<br>本论文作者发现理解 Dropout 与 BN 之间冲突的关键是网络状态切换过程中存在神经方差的（neural variance）不一致行为。试想若有图一中的神经响应 X，当网络从训练转为测试时，Dropout 可以通过其随机失活保留率（即 p）来缩放响应，并在学习中改变神经元的方差，而 BN 仍然维持 X 的统计滑动方差。这种方差不匹配可能导致数值不稳定（见下图中的红色曲线）。而随着网络越来越深，最终预测的数值偏差可能会累计，从而降低系统的性能。简单起见，作者们将这一现象命名为「方差偏移」。事实上，如果没有 Dropout，那么实际前馈中的神经元方差将与 BN 所累计的滑动方差非常接近（见下图中的蓝色曲线），这也保证了其较高的测试准确率。</p>
<h3 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h3><p>Dropout 在训练和测试时都需要嘛？<br>Dropout 在训练时采用，是为了减少神经元对部分上层神经元的依赖，类似将多个不同网络结构的模型集成起来，减少过拟合的风险。<br>而在测试时，应该用整个训练好的模型，因此不需要dropout。</p>
<h1 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h1><p>Word2vec<br>神经网络嵌入的主要用途有三种：<br>在嵌入空间中找到最近邻。<br>作为有监督的机器学习模型的输入。<br>挖掘变量间的关系。<br>利用神经网络嵌入，我们能将Wikipedia中的37000多本书转换为至多包含50个数值的向量。<br>神经网络嵌入还克服了独热编码的局限性。</p>
<h1 id="FocalLoss"><a href="#FocalLoss" class="headerlink" title="FocalLoss"></a>FocalLoss</h1><p>Focal loss主要是为了解决one-stage目标检测中正负样本比例严重失衡的问题。该损失函数降低了大量简单负样本在训练中所占的权重，也可理解为一种困难样本挖掘。<br>Focal loss是在交叉熵损失函数基础上进行的修改，首先回顾二分类交叉上损失：<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131412631.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131412631.png" class="lazyload" title="enter description here"></a><br> 是经过激活函数的输出，所以在0-1之间。可见普通的交叉熵对于正样本而言，输出概率越大损失越小。对于负样本而言，输出概率越小则损失越小。此时的损失函数在大量简单样本的迭代过程中比较缓慢且可能无法优化至最优。那么Focal loss是怎么改进的呢？<br> <a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131428118.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131428118.png" class="lazyload" title="enter description here"></a><br> 首先在原有的基础上加了一个因子，其中gamma>0使得减少易分类样本的损失。使得更关注于困难的、错分的样本。<br>例如gamma为2，对于正类样本而言，预测结果为0.95肯定是简单样本，所以（1-0.95）的gamma次方就会很小，这时损失函数值就变得更小。而预测概率为0.3的样本其损失相对很大。对于负类样本而言同样，预测0.1的结果应当远比预测0.7的样本损失值要小得多。对于预测概率为0.5时，损失只减少了0.25倍，所以更加关注于这种难以区分的样本。这样减少了简单样本的影响，大量预测概率很小的样本叠加起来后的效应才可能比较有效。<br>此外，加入平衡因子alpha，用来平衡正负样本本身的比例不均：文中alpha取0.25，即正样本要比负样本占比小，这是因为负例易分。<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131439172.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131439172.png" class="lazyload" title="enter description here"></a><br>只添加alpha虽然可以平衡正负样本的重要性，但是无法解决简单与困难样本的问题。<br>gamma调节简单样本权重降低的速率，当gamma为0时即为交叉熵损失函数，当gamma增加时，调整因子的影响也在增加。实验发现gamma为2是最优。</p>
<h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><p>深度残差网络。如果深层网络的后面那些层是恒等映射，那么模型就退化为一个浅层网络。那现在要解决的就是学习恒等映射函数了。 但是直接让一些层去拟合一个潜在的恒等映射函数H(x) = x，比较困难，这可能就是深层网络难以训练的原因。但是，如果把网络设计为H(x) = F(x) + x,如下图。我们可以转换为学习一个残差函数F(x) = H(x) - x. 只要F(x)=0，就构成了一个恒等映射H(x) = x. 而且，拟合残差肯定更加容易。<br>通俗的理解：<br>    理论上深层的神经网络一定比浅层的要好，比如深层网络A，浅层网络B，A的前几层完全复制B，A的后几层都不再改变B的输出，那么效果应该是和B是一样的。也就是说，A的前几层就是B，后几层是线性层。但是实验发现，超过一定界限之后，深层网络的效果比浅层的还差。一个可能的解释是：理论上，我们可以让A的后几层输入等于输出，但实际训练网络时，这个线性关系很难学到。既然如此，我们把这个线性关系直接加到网络的结构当中去，那么效果至少不必浅层网络差。也就是说，Resnet让深层神经网络更容易被训练了。</p>
<p>一方面: ResNet解决的不是梯度弥散或爆炸问题，kaiming的论文中也说了:臭名昭著的梯度弥散/爆炸问题已经很大程度上被normalized initialization and intermediate normalization layers解决了;<br>另一方面: 由于直接增加网络深度的(plain)网络在训练集上会有更高的错误率，所以更深的网络并没有过拟合，也就是说更深的网络效果不好，是因为网络没有被训练好，至于为啥没有被训练好。<br>F是求和前网络映射，H是从输入到求和后的网络映射。比如把5映射到5.1，那么引入残差前是F’(5)=5.1，引入残差后是H(5)=5.1, H(5)=F(5)+5, F(5)=0.1。这里的F’和F都表示网络参数映射，引入残差后的映射对输出的变化更敏感。比如s输出从5.1变到5.2，映射F’的输出增加了1/51=2%，而对于残差结构输出从5.1到5.2，映射F是从0.1到0.2，增加了100%。明显后者输出变化对权重的调整作用更大，所以效果更好。残差的思想都是去掉相同的主体部分，从而突出微小的变化，看到残差网络我第一反应就是差分放大器。</p>
<h1 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h1><ol>
<li>BN是在batch上，对N、H、W做归一化，而保留通道 C 的维度。BN对较小的batch size效果不好。BN适用于固定深度的前向神经网络，如CNN，不适用于RNN；</li>
<li>LN在通道方向上，对C、H、W归一化，主要对RNN效果明显；</li>
<li>IN在图像像素上，对H、W做归一化，用在风格化迁移；</li>
<li>GN将channel分组，然后再做归一化。</li>
</ol>
<h1 id="数据不平衡"><a href="#数据不平衡" class="headerlink" title="数据不平衡"></a>数据不平衡</h1><ol>
<li>设置损失函数的权重</li>
<li>下采样/欠采样</li>
<li>Edited Nearest Neighber(ENN)</li>
<li>Repeated Edited Nearest Neighber(RENN)</li>
<li>Tomek Link Removal</li>
<li>过采样/上采样</li>
<li>SMOTE算法</li>
<li>异常点检测</li>
<li>可以扩大数据集吗</li>
<li>尝试其它评价指标</li>
<li>尝试产生人工数据样本</li>
<li>尝试不同的分类算法</li>
<li>尝试对模型进行惩罚</li>
<li>尝试一个新的角度理解问题<h1 id="蓄水池算法"><a href="#蓄水池算法" class="headerlink" title="蓄水池算法"></a>蓄水池算法</h1>假设数据序列的规模为 n，需要采样的数量的为 k首先构建一个可容纳 k个元素的数组，将序列的前 k个元素放入数组中。然后从第 k+1个元素开始，以k/n的概率来决定该元素是否被替换到数组中（数组中的元素被替换的概率是相同的）。 当遍历完所有元素之后，数组中剩下的元素即为所需采取的样本。<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131622043.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583131622043.png" class="lazyload" title="enter description here"></a></li>
</ol>
</body></html></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Cqz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://mega-cqz.github.io/2020/02/28/DLLearn/">https://mega-cqz.github.io/2020/02/28/DLLearn/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://mega-cqz.github.io">世界で一番おひめさま</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%9D%A2%E8%AF%95/">深度学习,面试    </a></div><div class="post_share"><div class="social-share" data-image="/img/Fate.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/03/01/Redis/"><img class="prev_cover lazyload" data-src="/img/Fate.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>Redis</span></div></a></div><div class="next-post pull_right"><a href="/2020/02/28/mlLearn/"><img class="next_cover lazyload" data-src="/img/Fate.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>机器学习</span></div></a></div></nav></div></main><footer id="footer" style="background-image: url(/img/Fate.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By Cqz</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><script id="ribbon_piao" mobile="true" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/click_heart.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/ClickShowText.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"left","width":350,"height":500},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>