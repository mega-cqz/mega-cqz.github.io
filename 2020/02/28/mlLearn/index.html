<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>机器学习 | 世界で一番おひめさま</title><meta name="description" content="机器学习"><meta name="keywords" content="机器学习"><meta name="author" content="Cqz"><meta name="copyright" content="Cqz"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="机器学习"><meta name="twitter:description" content="机器学习"><meta name="twitter:image" content="https://mega-cqz.github.io/img/Fate.jpg"><meta property="og:type" content="article"><meta property="og:title" content="机器学习"><meta property="og:url" content="https://mega-cqz.github.io/2020/02/28/mlLearn/"><meta property="og:site_name" content="世界で一番おひめさま"><meta property="og:description" content="机器学习"><meta property="og:image" content="https://mega-cqz.github.io/img/Fate.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://mega-cqz.github.io/2020/02/28/mlLearn/"><link rel="prev" title="深度学习" href="https://mega-cqz.github.io/2020/02/28/DLLearn/"><link rel="next" title="Spring面试" href="https://mega-cqz.github.io/2020/02/28/spring/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">世界で一番おひめさま</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 清单</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/%E9%BB%84%E6%BC%AB%E8%80%81%E5%B8%88.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">12</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">12</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 清单</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#判别方法"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">判别方法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#评价标准"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">评价标准</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#通用标准"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">通用标准</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#特化标准"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">特化标准</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#ROC"><span class="toc_mobile_items-number">2.2.1.</span> <span class="toc_mobile_items-text">ROC</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#MAP"><span class="toc_mobile_items-number">2.2.2.</span> <span class="toc_mobile_items-text">MAP</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#AUC"><span class="toc_mobile_items-number">2.2.3.</span> <span class="toc_mobile_items-text">AUC</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#NDCG"><span class="toc_mobile_items-number">2.2.4.</span> <span class="toc_mobile_items-text">NDCG</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#AUC和NDCG的区别："><span class="toc_mobile_items-number">2.2.5.</span> <span class="toc_mobile_items-text">AUC和NDCG的区别：</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#损失函数"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">损失函数</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#面试：为什么用交叉熵"><span class="toc_mobile_items-number">2.4.</span> <span class="toc_mobile_items-text">面试：为什么用交叉熵</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#朴素贝叶斯"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">朴素贝叶斯</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#最大似然估计与最大后验概率"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">最大似然估计与最大后验概率</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#LR回归与SVM"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">LR回归与SVM</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#LR"><span class="toc_mobile_items-number">5.1.</span> <span class="toc_mobile_items-text">LR</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#SVM"><span class="toc_mobile_items-number">5.2.</span> <span class="toc_mobile_items-text">SVM</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#SVM与LR区别"><span class="toc_mobile_items-number">5.3.</span> <span class="toc_mobile_items-text">SVM与LR区别</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#聚类"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">聚类</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Kmeans与Kmeans"><span class="toc_mobile_items-number">6.1.</span> <span class="toc_mobile_items-text">Kmeans与Kmeans++</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#DBScan"><span class="toc_mobile_items-number">6.2.</span> <span class="toc_mobile_items-text">DBScan</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#正则化"><span class="toc_mobile_items-number">7.</span> <span class="toc_mobile_items-text">正则化</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#树算法"><span class="toc_mobile_items-number">8.</span> <span class="toc_mobile_items-text">树算法</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#ID3，C4-5，CART树"><span class="toc_mobile_items-number">8.1.</span> <span class="toc_mobile_items-text">ID3，C4.5，CART树</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#GBDT"><span class="toc_mobile_items-number">8.2.</span> <span class="toc_mobile_items-text">GBDT</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#XGBoost"><span class="toc_mobile_items-number">8.3.</span> <span class="toc_mobile_items-text">XGBoost</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#LightGBM"><span class="toc_mobile_items-number">8.4.</span> <span class="toc_mobile_items-text">LightGBM</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#单边梯度下降GOSS"><span class="toc_mobile_items-number">8.4.1.</span> <span class="toc_mobile_items-text">单边梯度下降GOSS</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#集成学习"><span class="toc_mobile_items-number">9.</span> <span class="toc_mobile_items-text">集成学习</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#降维"><span class="toc_mobile_items-number">10.</span> <span class="toc_mobile_items-text">降维</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#判别方法"><span class="toc-number">1.</span> <span class="toc-text">判别方法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#评价标准"><span class="toc-number">2.</span> <span class="toc-text">评价标准</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#通用标准"><span class="toc-number">2.1.</span> <span class="toc-text">通用标准</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特化标准"><span class="toc-number">2.2.</span> <span class="toc-text">特化标准</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ROC"><span class="toc-number">2.2.1.</span> <span class="toc-text">ROC</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MAP"><span class="toc-number">2.2.2.</span> <span class="toc-text">MAP</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AUC"><span class="toc-number">2.2.3.</span> <span class="toc-text">AUC</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NDCG"><span class="toc-number">2.2.4.</span> <span class="toc-text">NDCG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AUC和NDCG的区别："><span class="toc-number">2.2.5.</span> <span class="toc-text">AUC和NDCG的区别：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#损失函数"><span class="toc-number">2.3.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#面试：为什么用交叉熵"><span class="toc-number">2.4.</span> <span class="toc-text">面试：为什么用交叉熵</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#朴素贝叶斯"><span class="toc-number">3.</span> <span class="toc-text">朴素贝叶斯</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#最大似然估计与最大后验概率"><span class="toc-number">4.</span> <span class="toc-text">最大似然估计与最大后验概率</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#LR回归与SVM"><span class="toc-number">5.</span> <span class="toc-text">LR回归与SVM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#LR"><span class="toc-number">5.1.</span> <span class="toc-text">LR</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVM"><span class="toc-number">5.2.</span> <span class="toc-text">SVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVM与LR区别"><span class="toc-number">5.3.</span> <span class="toc-text">SVM与LR区别</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#聚类"><span class="toc-number">6.</span> <span class="toc-text">聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kmeans与Kmeans"><span class="toc-number">6.1.</span> <span class="toc-text">Kmeans与Kmeans++</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DBScan"><span class="toc-number">6.2.</span> <span class="toc-text">DBScan</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#正则化"><span class="toc-number">7.</span> <span class="toc-text">正则化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#树算法"><span class="toc-number">8.</span> <span class="toc-text">树算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ID3，C4-5，CART树"><span class="toc-number">8.1.</span> <span class="toc-text">ID3，C4.5，CART树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GBDT"><span class="toc-number">8.2.</span> <span class="toc-text">GBDT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#XGBoost"><span class="toc-number">8.3.</span> <span class="toc-text">XGBoost</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LightGBM"><span class="toc-number">8.4.</span> <span class="toc-text">LightGBM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#单边梯度下降GOSS"><span class="toc-number">8.4.1.</span> <span class="toc-text">单边梯度下降GOSS</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#集成学习"><span class="toc-number">9.</span> <span class="toc-text">集成学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#降维"><span class="toc-number">10.</span> <span class="toc-text">降维</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(/img/Fate.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">机器学习</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-02-28<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-03-02</time><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><h1 id="判别方法"><a href="#判别方法" class="headerlink" title="判别方法"></a>判别方法</h1><p>由数据直接学习决策函数 Y = f（X），或者由条件分布概率 P（Y|X）作为预测模型，即判别模型。<br>生成方法：由数据学习联合概率密度分布函数 P（X,Y）,然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型。<br>由生成模型可以得到判别模型，但由判别模型得不到生成模型。<br>常见的判别模型有：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boosting、条件随机场<br>常见的生成模型有：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机</p>
<h1 id="评价标准"><a href="#评价标准" class="headerlink" title="评价标准"></a>评价标准</h1><h2 id="通用标准"><a href="#通用标准" class="headerlink" title="通用标准"></a>通用标准</h2><p>偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了算法本身的拟合能力。<br>方差度量了同样大小的训练集的变动所导致的学习性能变化，即刻画了数据扰动所造成的影响。<br>噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。<br>泛化误差解释:bais^2+variance+noise:<br>泛化误差的意义，其实就是在训练后的模型，想来看一看这个模型具不具备代表性</p>
<p>准确率<br>预测结果中，究竟有多少是真的正？（找出来的对的比例）<br>P=TP/TP+FP<br>召回率<br>所有正样本中，你究竟预测对了多少？（找回来了几个）<br>R=TP/TP+FN</p>
<p>平衡点（Break-Even Point, BEP）<br>就是找一个 准确率 = 召回率 的值，就像上面的图那样。<br>F1度量<br>F1是准确率和召回率的调和平均，即是1/F1=1/2 ×(1/P+1/R)<br>，换算下：<br>F1=2PR/(P+R)</p>
<h2 id="特化标准"><a href="#特化标准" class="headerlink" title="特化标准"></a>特化标准</h2><h3 id="ROC"><a href="#ROC" class="headerlink" title="ROC"></a>ROC</h3><p>ROC曲线的横坐标为false positive rate（FPR）即负类样本中被判定为正类的比例，也就是传说中的误纳率<br>纵坐标为true positive rate（TPR）即正类样本中被判定为正类的样本，1-TPR也就是传说中的误拒率<br>既然已经这么多评价标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。AUC对样本的比例变化有一定的容忍性。AUC的值通常在0.6-0.85之间。</p>
<h3 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h3><p>MAP是什么<br>多标签图像分类任务中图片的标签不止一个，因此评价不能用普通单标签图像分类的标准，即mean accuracy，该任务采用的是和信息检索中类似的方法—mAP（mean Average Precision），虽然其字面意思和mean accuracy看起来差不多，但是计算方法要繁琐得多。(排序，上到下选n个数，分别计算里头的召回之类)</p>
<p>计算AP<br>接下来说说AP的计算，此处参考的是PASCAL VOC CHALLENGE的计算方法。首先设定一组阈值，[0, 0.1, 0.2, …, 1]。然后对于recall大于每一个阈值（比如recall>0.3），我们都会得到一个对应的最大precision。这样，我们就计算出了11个precision。AP即为这11个precision的平均值。这种方法英文叫做11-point interpolated average precision。<br>AP衡量的是学出来的模型在给定类别上的好坏，而mAP衡量的是学出的模型在所有类别上的好坏，得到AP后mAP的计算就变得很简单了，就是取所有AP的平均值。</p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>简单来说其实就是随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率。</p>
<p>group auc的评价指标 group auc实际是计算每个用户的auc，然后加权平均，最后得到group auc，这样就能减少不同用户间的排序结果不太好比较这一影响。<br>mAP)只是把每个类别的AP都算了一遍，再取平均值<br>因此，AP是针对单个类别的，mAP是针对所有类别的</p>
<h3 id="NDCG"><a href="#NDCG" class="headerlink" title="NDCG"></a>NDCG</h3><p>NDCG这个名字可能有点吓人，但其背后的思想却很简单。一个推荐系统返回一些项并形成一个列表，我们想要计算这个列表有多好。每一项都有一个相关的评分值，通常这些评分值是一个非负数。这就是gain（增益）。此外，对于这些没有用户反馈的项，我们通常设置其增益为0。<br>现在，我们把这些分数相加，也就是Cumulative Gain（累积增益）。我们更愿意看那些位于列表前面的最相关的项，因此，在把这些分数相加之前，我们将每项除以一个递增的数（通常是该项位置的对数值），也就是折损值，并得到DCG。<br>在用户与用户之间，DCGs没有直接的可比性，所以我们要对它们进行归一化处理。最糟糕的情况是，当使用非负相关评分时DCG为0。为了得到最好的，我们把测试集中所有的条目置放在理想的次序下，采取的是前K项并计算它们的DCG。然后将原DCG除以理想状态下的DCG并得到NDCG@K，它是一个0到1之间的数。</p>
<h3 id="AUC和NDCG的区别："><a href="#AUC和NDCG的区别：" class="headerlink" title="AUC和NDCG的区别："></a>AUC和NDCG的区别：</h3><p>1、AUC的含义：把正样本排在负样本前的概率。AUC关注的是全局的排序，只要正样本排在负样本之前，就可以得分。并没有加权。<br>2、NDCG也是关注排序，但是NDCG关注的是，加权排序。比如我们希望top10的排序准确度，要比bottom10的排序准确度重要。对于这种加权排序，NDCG会更加合适。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>回归损失<br>均方误差/平方损失/L2 损失<br>平均绝对误差/L1 损失<br>平均偏差误差<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130077046.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130077046.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130084175.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130084175.png" class="lazyload"></a><br>分类损失<br>Hinge Loss/多分类 SVM 损失<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130097170.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130097170.png" class="lazyload"></a><br>交叉熵损失/负对数似然<br>若有两个概率分布p(x)和q(x)，通过q来表示p的交叉熵为：(注意，p和q呼唤位置后，交叉熵是不同的)<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130107850.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130107850.png" class="lazyload"></a><br>假设有一个三分类问题，某个样例的正确答案是(1，0，0)，某个模型经过softmax回归之后的预测答案是(0.5，0.4，0.1)，那么他们的交叉熵为：<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130145375.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130145375.png" class="lazyload"></a><br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130124359.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583130124359.png" class="lazyload"></a></p>
<h2 id="面试：为什么用交叉熵"><a href="#面试：为什么用交叉熵" class="headerlink" title="面试：为什么用交叉熵"></a>面试：为什么用交叉熵</h2><p>Mse（均方误差）相关：其实mse是万能的loss函数，每个模型都可以用mse作为loss函数的，那为什么lr不用mse呢？<br>由于均方误差（MSE）在误差较大点时的损失远大于平均绝对误差（MAE），它会给异常值赋予更大的权重，模型会全力减小异常值造成的误差，从而使得模型的整体表现下降。</p>
<p>交叉熵使得梯度与绝对误差成正比，二范数导致梯度变得扭曲参考资料。<br>总结：<br>损失函数先增后减</p>
<ol>
<li>神经网络中如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛，如果预测值与实际值的误差小，各种参数调整的幅度就要小，从而减少震荡。</li>
<li>使用平方误差损失函数，误差增大参数的梯度会增大，但是当误差很大时，参数的梯度就会又减小了。</li>
<li>使用交叉熵损失是函数，误差越大参数的梯度也越大，能够快速收敛。</li>
</ol>
<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><p>基于特征条件独立假设学习输入/输出的联合概率分布，然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。<br>•    不同于其它分类器，朴素贝叶斯是一种基于概率理论的分类算法；<br>•    特征之间的条件独立性假设，显然这种假设显得“粗鲁”而不符合实际，这也是名称中“朴素”的由来。然而事实证明，朴素贝叶斯在有些领域很有用，比如垃圾邮件过滤；<br>•    在具体的算法实施中，要考虑很多实际问题。比如因为“下溢”问题，需要对概率乘积取对数；再比如词集模型和词袋模型，还有停用词和无意义的高频词的剔除，以及大量的数据预处理问题，等等；<br>•    总体上来说，朴素贝叶斯原理和实现都比较简单，学习和预测的效率都很高，是一种经典而常用的分类算法。</p>
<h1 id="最大似然估计与最大后验概率"><a href="#最大似然估计与最大后验概率" class="headerlink" title="最大似然估计与最大后验概率"></a>最大似然估计与最大后验概率</h1><p>P(x|θ)<br>输入有两个：x表示某一个具体的数据；θ表示模型的参数。如果θ是已知确定的，x是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。如果x是已知确定的，θ是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。最大似然估计是求参数θ, 使似然函数P(x0|θ)最大。最大后验概率估计则是想求θ使P(x0|θ)P(θ)最大。求得的θ不单单让似然函数大，θ自己出现的先验概率也得大。</p>
<h1 id="LR回归与SVM"><a href="#LR回归与SVM" class="headerlink" title="LR回归与SVM"></a>LR回归与SVM</h1><h2 id="LR"><a href="#LR" class="headerlink" title="LR"></a>LR</h2><p>LR回归：<br>逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。<br>LR的应用和优缺点<br>   优点：1）适合需要得到一个分类概率的场景。2）计算代价不高，容易理解实现。LR在时间和内存需求上相当高效。它可以应用于分布式数据，并且还有在线算法实现，用较少的资源处理大型数据。3）LR对于数据中小噪声的鲁棒性很好，并且不会受到轻微的多重共线性的特别影响。（严重的多重共线性则可以使用逻辑回归结合L2正则化来解决，但是若要得到一个简约模型，L2正则化并不是最好的选择，因为它建立的模型涵盖了全部的特征。）<br>   缺点：1）容易欠拟合，分类精度不高。2）数据特征有缺失或者特征空间很大时表现效果并不好。</p>
<p>工业应用：<br>在这里我们总结了逻辑回归应用到工业界当中一些优点：<br>•    形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。<br>•    模型效果不错。在工程上是可以接受的（作为baseline)，如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。<br>•    训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过堆机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。<br>•    资源占用小,尤其是内存。因为只需要存储各个维度的特征值，。<br>•    方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)。<br>      但是逻辑回归本身也有许多的缺点:<br>•    准确率并不是很高。因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布。<br>•    很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比 10000:1.我们把所有样本都预测为正也能使损失函数的值比较小。但是作为一个分类器，它对正负样本的区分能力不会很好。<br>•    处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题 。<br>•    逻辑回归本身无法筛选特征。有时候，我们会用gbdt来筛选特征，然后再上逻辑回归。<br>公式推导：<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583128407602.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583128407602.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583128438993.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583128438993.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583128450448.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583128450448.png" class="lazyload"></a><br>LR做非线性<br>对特征做非线性变换 比如kernel 当然可以 但那就不是lr了 或者一个神经网络 最后一层看成是lr 前面看成是提特征，把特征离散化，然后做组合特征，可以实现一定程度的非线性，但是和svm是不一样的，svm使用kernel不容易过拟合，而lr更容易过拟合。因为在lr里面vc dimension是随变量数线性增长的</p>
<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p>SVM的学习算法有两种解释：1. 间隔最大化与拉格朗日对偶；2. Hinge Loss,3.SMO(每次取2个a，更新参数)</p>
<p>SVM为什么转为对偶问题<br>  对偶问题将原始问题中的约束转为了对偶问题中的等式约束<br>  方便核函数的引入<br>    改变了问题的复杂度。由求特征向量w转化为求比例系数a，在原始问题下，求解的复杂度与样本的维度有关，即w的维度。在对偶问题下，只与样本数量有关。<br>求解更高效，因为只用求解比例系数a，而比例系数a只有支持向量才为非0，其他全为0.<br>对偶问题有非常良好的性质，以下列举几个：<br>•    对偶问题的对偶是原问题；<br>•    无论原始问题是否是凸的，对偶问题都是凸优化问题；<br>•    对偶问题可以给出原始问题一个下界；<br>•    当满足一定条件时，原始问题与对偶问题的解是完全等价的；<br>无论原始问题是什么形式，对偶问题总是一个凸优化的问题，这样对于那些难以求解的原始问题 （甚至是 NP 问题），均可以通过转化为偶问题，通过优化这个对偶问题来得到原始问题的一个下界<br>逻辑回归处理非线性的数据，其中一种方式便是组合不同特征，增强逻辑回归对非线性分布的拟合能力。</p>
<p>SVM不足：<br>1.SVM算法对大规模训练样本难以实施，由于SVM是借助二次规划来求解支持向量，而求解二次规划将涉及m阶矩阵的计算（m为样本的个数），当m数目很大时该矩阵的存储和计算将耗费大量的机器内存和运算时间。<br>2.用SVM解决多分类问题存在困难<br>3.没有概率</p>
<p>如何理解核函数能把低维映射到高维<br>关键：因为有泰勒展开<br>严格说是为什么高斯核函数能够将低维映射到无穷维<br>对于高斯核为什么可以将数据映射到无穷多维，我们可以从泰勒展开式的角度来解释，</p>
<p>线性核，主要用于线性可分的情况，我们可以看到特征空间到输入空间的维度是一样的，其参数少速度快，对于线性可分数据，其分类效果很理想，因此我们通常首先尝试用线性核函数来做分类，看看效果如何，如果不行再换别的<br>多项式核函数可以实现将低维的输入空间映射到高纬的特征空间，但是多项式核函数的参数多，当多项式的阶数比较高的时候，核矩阵的元素值将趋于无穷大或者无穷小，计算复杂度会大到无法计算。<br>高斯径向基函数是一种局部性强的核函数，其可以将一个样本映射到一个更高维的空间内，该核函数是应用最广的一个，无论大样本还是小样本都有比较好的性能，而且其相对于多项式核函数参数要少，因此大多数情况下在不知道用什么核函数的时候，优先使用高斯核函数。<br>采用sigmoid核函数，支持向量机实现的就是一种多层神经网络。<br>因此，在选用核函数的时候，如果我们对我们的数据有一定的先验知识，就利用先验来选择符合数据分布的核函数；如果不知道的话，通常使用交叉验证的方法，来试用不同的核函数，误差最下的即为效果最好的核函数，或者也可以将多个核函数结合起来，形成混合核函数。在吴恩达的课上，也曾经给出过一系列的选择核函数的方法：</p>
<h2 id="SVM与LR区别"><a href="#SVM与LR区别" class="headerlink" title="SVM与LR区别"></a>SVM与LR区别</h2><p>相同点：<br>1、都是有监督的分类算法；<br>2、如果不考虑核函数，LR和SVM都是线性分类算法。<br>它们的分类决策面都是线性的。<br>3、LR和SVM都是判别式模型。<br>LR、SVM、决策树等判别式模型直接生成一个表示P(Y|X)或者Y=f(X)的判别函数。而生成式模型，例如朴素贝叶斯（NB），隐马尔可夫链（HMM），都是先计算联合概率分布P(Y,X)，然后通过贝叶斯公式转化为P(Y|X)</p>
<p>LR与SVM的不同点：<br>1、本质上是loss函数不同，或者说分类的原理不同。<br>LR的目标是最小化模型分布和经验分布之间的交叉熵：<br>LR基于概率理论中的极大似然估计。首先假设样本为0或者1的概率可以用sigmoid函数来表示，然后通过极大似然估计的方法估计出参数的值，即让模型产生的分布P(Y|X)尽可能接近训练数据的分布。<br>SVM的目标是最大化分类间隔（硬SVM），或者最大化间隔加距离（软SVM）SVM基于几何间隔最大化原理，认为几何间隔最大的分类面为最优分类面 。<br>2、SVM是结构风险最小化，LR则是经验风险最小化。<br>结构风险最小化就是在训练误差和模型复杂度之间寻求平衡，防止过拟合，减小泛化误差。为了达到结构风险最小化的目的，最常用的方法就是添加正则项。<br>SVM的loss函数的第一项可看作L2正则项；LR需要加入正则化项。<br>3、SVM只考虑分界面附近的少数点，而LR则考虑所有点。<br>影响SVM决策面的样本点只有少数的支持向量。在支持向量外添加或减少任何样本点，对分类决策面没有任何影响。<br>在LR中，每个样本点都会影响决策面。决策面会倾向于远离样本数量较多的类别。如果不同类别之间的数量严重不平衡，一般需要先对数据做balancing。<br>4、SVM不能产生概率，LR可以产生概率。<br>5、在解决非线性问题时，SVM可采用核函数的机制，而LR通常不采用核函数的方法。<br>SVM只有少数几个样本需要参与核计算（即kernal machine解的系数是稀疏的）。<br>LR里每个样本点都要参与核计算，计算复杂度太高，故LR通常不用核函数。<br>6、SVM计算复杂，但效果比LR好，适合小数据集；LR计算简单，适合大数据集，可以在线训练。</p>
<p>应用：<br>如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；<br>如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；<br>如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况</p>
<h1 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h1><h2 id="Kmeans与Kmeans"><a href="#Kmeans与Kmeans" class="headerlink" title="Kmeans与Kmeans++"></a>Kmeans与Kmeans++</h2><p>k值的选择<br> 最常用最简单的方法可视化数据，然后观察出聚类聚成几类比较合适<br>•  绘制出k-average with cluster distance to centroid的图表，观察随着k值的增加，曲线的下降情况，当曲线不再“急剧”下降时，就是合适的k值<br>•  计算不同k值下kmeans算法的BIC和AIC值，BIC或AIC值越小，选择该k值<br>•  使用 Canopy算法先进行粗略的聚类，产生的簇的个数，作为kmeans算法的k值<br>•  使用x-means方法结合BIC准则去判定簇的个数，也就是k值<br>•  使用Gap Statistic公式来确定k值<br>•  使用轮廓系数(silhouette coefficient)来确定，选择使系数较大所对应的k值<br>•  使用交叉验证来确定使目标函数（距中心的距离的平方差）变小的k值<br>•  利用Affinity propagation的方法估计最优的聚类数目，进一步进行kmeans的算法<br>•  利用层次聚类，可视化后认为地观察认定可聚为几类，确定k值</p>
<p>k-means算法中起点是随机或者认为给定的，如果初始类中心发生改变，可能会导致结果改变解决问题的方法：<br>1、把初始随机数进行固定2、自己设定初始随机种子</p>
<p>轮廓系数Average silhouette method<br>轮廓系数是类的密集与分散程度的评价指标。<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129047922.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129047922.png" class="lazyload"></a><br> a(i)是测量组内的相似度,b(i)是测量组间的相似度，s(i)范围从-1到1，值越大说明组内吻合越高，组间距离越远——也就是说，轮廓系数值越大，聚类效果越好[9] 求出所有样本的轮廓系数后再求平均值就得到了平均轮廓系数。平均轮廓系数的取值范围为[-1,1]，且簇内样本的距离越近，簇间样本距离越远，平均轮廓系数越大，聚类效果越好。那么，很自然地，平均轮廓系数最大的k便是最佳聚类数。</p>
<p>K-means++按照如下的思想选取K个聚类中心：<br>•    假设已经选取了n个初始聚类中心(0<n<k)，则在选取第n+1个聚类中心时：距离当前n个聚类中心越远的点会有更高的概率被选为第n+1个聚类中心。<br>•    在选取第一个聚类中心(n=1)时同样通过随机的方法。</n<k)，则在选取第n+1个聚类中心时：距离当前n个聚类中心越远的点会有更高的概率被选为第n+1个聚类中心。<br></p>
<h2 id="DBScan"><a href="#DBScan" class="headerlink" title="DBScan"></a>DBScan</h2><p>DBSCAN（Density-Based Spatial Clustering of Applications with Noise，具有噪声的基于密度的聚类方法）是一种基于密度的空间聚类算法。 该算法将具有足够密度的区域划分为簇，并在具有噪声的空间数据库中发现任意形状的簇，它将簇定义为密度相连的点的最大集合。<br>•    聚类分为：基于划分、层次、密度、图形和模型五大类；<br>•    均值聚类k-means是基于划分的聚类， DBSCAN是基于密度的聚类。区别为：</p>
<ol>
<li><p>k-means需要指定聚类簇数k，并且且初始聚类中心对聚类影响很大。k-means把任何点都归到了某一个类，对异常点比较敏感。DBSCAN能剔除噪声，需要指定邻域距离阈值eps和样本个数阈值MinPts，可以自动确定簇个数。</p>
</li>
<li><p>K均值和DBSCAN都是将每个对象指派到单个簇的划分聚类算法，但是K均值一般聚类所有对象，而DBSCAN丢弃被它识别为噪声的对象。</p>
</li>
<li><p>K均值很难处理非球形的簇和不同大小的簇。DBSCAN可以处理不同大小或形状的簇，并且不太受噪声和离群点的影响。当簇具有很不相同的密度时，两种算法的性能都很差。</p>
</li>
<li><p>K均值只能用于具有明确定义的质心（比如均值或中位数）的数据。DBSCAN要求密度定义（基于传统的欧几里得密度概念）对于数据是有意义的。</p>
</li>
<li><p>K均值算法的时间复杂度是O(m)，而DBSCAN的时间复杂度是O(m^2)。</p>
</li>
<li><p>DBSCAN多次运行产生相同的结果，而K均值通常使用随机初始化质心，不会产生相同的结果。</p>
</li>
<li><p>K均值DBSCAN和都寻找使用所有属性的簇，即它们都不寻找可能只涉及某个属性子集的簇。</p>
</li>
<li><p>K均值可以发现不是明显分离的簇，即便簇有重叠也可以发现，但是DBSCAN会合并有重叠的簇。</p>
</li>
<li><p>K均值可以用于稀疏的高维数据，如文档数据。DBSCAN通常在这类数据上的性能很差，因为对于高维数据，传统的欧几里得密度定义不能很好处理它们。</p>
</li>
<li><p>DBSCAN优点：</p>
</li>
<li><p>可以对任意形状的稠密数据集进行聚类，相对的，K-Means之类的聚类算法一般只适用于凸数据集。</p>
</li>
<li><p>可以在聚类的同时发现异常点，对数据集中的异常点不敏感。</p>
</li>
<li><p>聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。</p>
<p>DBSSCAN缺点：</p>
</li>
<li><p>如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。</p>
</li>
<li><p>如果样本集较大时，聚类收敛时间较长，此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进。</p>
</li>
<li><p>调参相对于传统的K-Means之类的聚类算法稍复杂，主要需要对距离阈值ϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响。</p>
</li>
</ol>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>weight decay（权值衰减）的使用既不是为了提高你所说的收敛精确度也不是为了提高收敛速度，其最终目的是防止过拟合。在损失函数中，weight decay是放在正则项（regularization）前面的一个系数，正则项一般指示模型的复杂度，所以weight decay的作用是调节模型复杂度对损失函数的影响，若weight decay很大，则复杂的模型损失函数的值也就大。</p>
<p>L1和L2(权重衰减。Weight decay)正则都是比较常见和常用的正则化项，都可以达到防止过拟合的效果。L1正则化的解具有稀疏性，可用于特征选择。L2正则化的解都比较小,分类间隔变大，抗扰动能力强,正则化。L2保证矩阵满秩<br>L1是拉普拉斯分布，L2是高斯分布<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129103677.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129103677.png" class="lazyload"></a></p>
<p>拉普拉斯分布在参数w=0点的概率最高，因此L1正则化相比于L2正则化更容易使参数为0；高斯分布在零附近的概率较大，因此L2正则化相比于L1正则化更容易使参数分布在一个很小的范围内。<br>L1的权值更新公式为wi = wi – η * 1, 权值每次更新都固定减少一个特定的值(学习速率)，那么经过若干次迭代之后，权值就有可能减少到0。<br>L2的权值更新公式为wi = wi – η * wi，虽然权值不断变小，但每次减小的幅度不断降低，所以很快会收敛到较小的值但不为0。<br>L1范数是指向量中各个元素绝对值之和,为什么L1范数会使权值稀疏？有人可能会这样给你回答“它是L0范数的最优凸近似”。实际上，还存在一个更美的回答：任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。这说是这么说，W的L1范数是绝对值，|w|在w=0处是不可微<br>L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。为什么越小的参数说明模型越简单？我也不懂，我的理解是：限制了参数很小，实际上就限制了多项式某些分量的影响很小（看上面线性回归的模型的那个拟合的图），这样就相当于减少参数个数。</p>
<p>偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了算法本身的拟合能力。<br>方差度量了同样大小的训练集的变动所导致的学习性能变化，即刻画了数据扰动所造成的影响。<br>噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。<br>泛化误差解释:bais^2+variance+noise:<br>泛化误差的意义，其实就是在训练后的模型，想来看一看这个模型具不具备代表性</p>
<h1 id="树算法"><a href="#树算法" class="headerlink" title="树算法"></a>树算法</h1><h2 id="ID3，C4-5，CART树"><a href="#ID3，C4-5，CART树" class="headerlink" title="ID3，C4.5，CART树"></a>ID3，C4.5，CART树</h2><p>ID3 信息增益 = 划分前熵 - 划分后熵。（正负用例再分开计算一次）<br>C4.5信息增益比 = 信息增益 /划分前熵（不分正负用例）<br>CART与ID3，C4.5不同之处在于CART生成的树必须是二叉树<br>Gini指数的计算不需要对数运算，更加高效<br>Gini指数更偏向于连续属性，熵更偏向于离散属性，<br>信息增益挑选大的，基尼选小的</p>
<h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p>gbdt通过多轮迭代,每轮迭代产生一个弱分类器，每个分类器在上一轮分类器的残差基础上进行训练。对弱分类器的要求一般是足够简单，并且是低方差和高偏差的。因为训练的过程是通过降低偏差来不断提高最终分类器的精度，（此处是可以证明的）。弱分类器一般会选择为CART TREE（也就是分类回归树）。由于上述高偏差和简单的要求 每个分类回归树的深度不会很深。最终的总分类器 是将每轮训练得到的弱分类器加权求和得到的（也就是加法模型）。<br>当CART是分类树时，采用GINI值作为节点分裂的依据；当CART是回归树时，采用样本的最小方差作为节点分裂的依据<br>结果是 ，第m棵树要拟合这个值，与残差相同。所以残差只是负梯度为平方损失时的特殊情况。</p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129520594.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129520594.png" class="lazyload"></a><br>生成多棵树，结果为树的叶子节点+和<br>是针对样本 X 每个可能的类都训练一个分类回归树。举例说明，目前样本有三类，也就是 K = 3。样本 x 属于 第二类。那么针对该样本 x 的分类结果，其实我们可以用一个 三维向量 [0,1,0] 来表示。0表示样本不属于该类，1表示样本属于该类。由于样本已经属于第二类了，所以第二类对应的向量维度为1，其他位置为0。<br>决策树算法的CART树都是回归树，不是基尼系数的, 这里面的核心是因为gbdt 每轮的训练是在上一轮的训练的残差基础之上进行训练的。这里的残差就是当前模型的负梯度值 。这个要求每轮迭代的时候，弱分类器的输出的结果相减是有意义的。残差相减是有意义的。</p>
<p>最初所有样本都在根节点，根节点输出值是所有目标值的均值。</p>
<p>GBDT中的树都是回归树，不是分类树，这点对理解GBDT相当重要（尽管GBDT调整后也可用于分类但不代表GBDT的树是分类树）。<br>具体到损失函数本身的选择也就是L的选择，有平方损失函数，0-1损失函数，对数损失函数等等。如果我们选择平方损失函数，那么这个差值其实就是我们平常所说的残差。<br>当损失函数是平方损失和指数损失函数时，梯度提升树每一步优化是很简单的，但是对于一般损失函数而言，往往每一步优化起来不那么容易，针对这一问题，Friedman提出了梯度提升树算法，这是利用最速下降的近似方法，其关键是利用损失函数的负梯度作为提升树算法中的残差的近似值。<br>GBDT的基本想法是让新的基模型（GBDT以CART分类回归树为基模型）去拟合前面模型的偏差，从而不断将加法模型的偏差降低。相比于经典的GBDT，xgboost做了一些改进，从而在效果和性能上有明显的提升（划重点面试常考）。第一，GBDT将目标函数泰勒展开到一阶，而xgboost将目标函数泰勒展开到了二阶(每个数据点在误差函数上的一阶导数 和二阶导数 )。保留了更多有关目标函数的信息，对提升效果有帮助。第二，GBDT是给新的基模型寻找新的拟合标签（前面加法模型的负梯度），而xgboost是给新的基模型寻找新的目标函数（目标函数关于新的基模型的二阶泰勒展开）。第三，xgboost加入了和叶子权重的L2正则化项，因而有利于模型获得更低的方差。第四，xgboost增加了自动处理缺失值特征的策略。通过把带缺失值样本分别划分到左子树或者右子树，比较两种方案下目标函数的优劣，从而自动对有缺失值的样本进行划分，无需对缺失特征进行填充预处理。传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。支持并行化，这是XGBoost的闪光点，虽然树与树之间是串行关系，但是同层级节点可并行。具体的对于某个节点，节点内选择最佳分裂点，候选分裂点计算增益用多线程并行。训练速度快。<br>公式推导：<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129646543.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129646543.png" class="lazyload"></a></p>
<h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>XGBoost使用了和CART回归树一样的想法，利用贪婪算法，遍历所有特征的所有特征划分点，不同的是使用上式目标函数值作为评价函数。具体做法就是分裂后的目标函数值比单子叶子节点的目标函数的增益，同时为了限制树生长过深，还加了个阈值，只有当增益大于该阈值才进行分裂。同时可以设置树的最大深度、当样本权重和小于设定阈值时停止生长去防止过拟合。<br>对于连续型特征值，当样本数量非常大，该特征取值过多时，遍历所有取值会花费很多时间，且容易过拟合。因此XGBoost思想是对特征进行分桶，即找到l个划分点，将位于相邻分位点之间的样本分在一个桶中。在遍历该特征的时候，只需要遍历各个分位点，从而计算最优划分。从算法伪代码中该流程还可以分为两种，全局的近似是在新生成一棵树之前就对各个特征计算分位点并划分样本，之后在每次分裂过程中都采用近似划分，而局部近似就是在具体的某一次分裂节点的过程中采用近似算法。<br>GBDT 最小化损失函数分裂，XGBoost计算出分裂前后损失函数的差值为，XGBoost采用最大化这个差值作为准则来进行决策树的构建，通过遍历所有特征的所有值，寻找使得损失函数前后差值最大的相对应分裂方式。此外由于损失函数前后存在差值一定是正的限制，此时γγ起到了一定的预剪枝效果。</p>
<p>XGBoost的优点<br>之所以XGBoost可以成为机器学习的大杀器，广泛用于数据科学竞赛和工业界，是因为它有许多优点：<br>1.使用许多策略去防止过拟合，如：正则化项、Shrinkage and Column Subsampling等。<br>2. 目标函数优化利用了损失函数关于待求函数的二阶导数<br>3.支持并行化，这是XGBoost的闪光点，虽然树与树之间是串行关系，但是同层级节点可并行。具体的对于某个节点，节点内选择最佳分裂点，候选分裂点计算增益用多线程并行。训练速度快。<br>4.添加了对稀疏数据的处理。<br>5.交叉验证，early stop，当预测结果已经很好的时候可以提前停止建树，加快训练速度。<br>6.支持设置样本权重，该权重体现在一阶导数g和二阶导数h，通过调整权重可以去更加关注一些样本。<br>Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率） </p>
<p>用xgboost/gbdt在在调参的时候把树的最大深度调成6就有很高的精度了。但是用DecisionTree/RandomForest的时候需要把树的深度调到15或更高。<br>xgboost还支持候选分位点切割，特征并行等，可以提升性能<br>1，是否要进行分裂？<br>根据树的剪枝策略的不同，这个问题有两种不同的处理。如果是预剪枝策略，那么只有当存在某种分裂方式使得分裂后目标函数发生下降，才会进行分裂。但如果是后剪枝策略，则会无条件进行分裂，等树生成完成后，再从上而下检查树的各个分枝是否对目标函数下降产生正向贡献从而进行剪枝。xgboost采用预剪枝策略，只有分裂后的增益大于0才会进行分裂。<br>2，选择什么特征进行分裂？<br>xgboost采用特征并行的方法进行计算选择要分裂的特征，即用多个线程，尝试把各个特征都作为分裂的特征，找到各个特征的最优分割点，计算根据它们分裂后产生的增益，选择增益最大的那个特征作为分裂的特征。<br>3，选择什么分裂点位？<br>xgboost选择某个特征的分裂点位的方法有两种，一种是全局扫描法，另一种是候选分位点法。<br>全局扫描法将所有样本该特征的取值按从小到大排列，将所有可能的分裂位置都试一遍，找到其中增益最大的那个分裂点，其计算复杂度和叶子节点上的样本特征不同的取值个数成正比。<br>而候选分位点法是一种近似算法，仅选择常数个（如256个）候选分裂位置，然后从候选分裂位置中找出最优的那个。<br>公式推导：<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129728316.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129728316.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129735206.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129735206.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129741597.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129741597.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129748549.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129748549.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129754511.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129754511.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129760472.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129760472.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129767875.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129767875.png" class="lazyload"></a></p>
<p><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129773550.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129773550.png" class="lazyload"></a></p>
<h2 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h2><p>LightGBM直方图算法的基本思想是先把连续的浮点特征值离散化成kk个整数，同时构造一个宽度为kk的直方图。在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点。在XGBoost中需要遍历所有离散化的值，而在这里只要遍历kk个直方图的值。使用直方图算法有很多优点。首先，最明显就是内存消耗的降低，直方图算法不仅不需要额外存储预排序的结果，而且可以只保存特征离散化后的值。<br>（2）一个容易观察到的现象：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的k个桶。利用这个方法，LightGBM可以在构造一个叶子的直方图后（父节点在上一轮就已经计算出来了），可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。<br>3）带深度限制的Leaf-wise的叶子生长策略<br>Level-wise过一次数据可以同时分裂同一层的叶子，容易进行多线程优化，也好控制模型复杂度，不容易过拟合。但实际上Level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销，因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。Leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。Leaf-wise的缺点是可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。　<br>　4）直接支持类别特征（即不需要做one-hot编码）<br>　　实际上大多数机器学习工具都无法直接支持类别特征，一般需要把类别特征，转化到多维的one-hot编码特征，降低了空间和时间的效率。而类别特征的使用是在实践中很常用的。基于这个考虑，LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外的one-hot编码展开。并在决策树算法上增加了类别特征的决策规则。在Expo数据集上的实验，相比0/1展开的方法，训练速度可以加速8倍，并且精度一致。<br>5）直接支持高效并行</p>
<p>LightGBM还具有支持高效并行的优点。LightGBM原生支持并行学习，目前支持特征并行和数据并行的两种。<br>　　1）特征并行的主要思想是在不同机器在不同的特征集合上分别寻找最优的分割点，然后在机器间同步最优的分割点。<br>　　2）数据并行则是让不同的机器先在本地构造直方图，然后进行全局的合并，最后在合并的直方图上面寻找最优分割点。<br>　　LightGBM针对这两种并行方法都做了优化，在特征并行算法中，通过在本地保存全部数据避免对数据切分结果的通信；在数据并行中使用分散规约 (Reduce scatter) 把直方图合并的任务分摊到不同的机器，降低通信和计算，并利用直方图做差，进一步减少了一半的通信量。 (数据量上去了就lgb，小一些就xgb)<br>3）LightGBM投票并行<br>LightGBM采用一种称为PV-Tree的算法进行投票并行(Voting Parallel)，本质上也是一种数据并行。<br>PV-Tree和普通的决策树差不多，只是在寻找最优切分点上有所不同。<br>    ①水平切分数据，不同的worker拥有部分数据。<br>    ②Local voting: 每个worker构建直方图，找到top-k个最优的本地划分特征<br>    ③Global voting: 中心节点聚合得到最优的top-2k个全局划分特征（top-2k是对各个worker选择特征的个数进行计数，取最多的2k个）<br>    ④Best Attribute Identification： 中心节点向worker收集这top-2k个特征的直方图，并进行合并，然后计算得到全局的最优划分<br>    ⑤中心节点将全局最优划分广播给所有的worker，worker进行本地划分。<br>XGBoost有三类参数：通用参数、学习目标参数、Booster参数<br>LightGBM：核心参数、学习控制参数、IO参数、目标参数、度量参数、网络参数、GPU参数、模型参数。其中比较重要的是【核心参数、学习控制参数、度量参数】</p>
<p>•    基于Histogram的决策树算法<br>•    带深度限制的Leaf-wise的叶子生长策略<br>•    直方图做差加速<br>•    支持类别特征<br>•    Cache命中率优化<br>•    基于直方图的稀疏特征多线程优化</p>
<p>LightGBM是一个梯度Boosting框架，使用基于决策树的学习算法。它可以说是分布式的，高效的，有以下优势：<br>　　1）更快的训练效率<br>　　2）低内存使用<br>　　3）更高的准确率<br>　　4）支持并行化学习<br>5）可以处理大规模数据<br>与常见的机器学习算法对比，速度是非常快的<br>关于XGboost的不足之处主要有：<br>　　1）每轮迭代时，都需要遍历整个训练数据多次。如果把整个训练数据装进内存则会限制训练数据的大小；如果不装进内存，反复地读写训练数据又会消耗非常大的时间。<br>　　2）预排序方法的时间和空间的消耗都很大<br><a href="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129825259.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="enter description here" class="fancybox"><img alt="enter description here" title="enter description here" data-src="https://raw.githubusercontent.com/mega-cqz/xiaoshujiang/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1583129825259.png" class="lazyload"></a></p>
<h3 id="单边梯度下降GOSS"><a href="#单边梯度下降GOSS" class="headerlink" title="单边梯度下降GOSS"></a>单边梯度下降GOSS</h3><p>GOSS是通过区分不同梯度的实例，保留较大梯度实例同时对较小梯度随机采样的方式减少计算量，从而达到提升效率的目的。<br>因为在提升树训练过程中目标函数学习的就是负梯度（近似残差），梯度小说明训练误差已经很小了，对这部分数据的进一步学习的效果不如对梯度大的样本进行学习的效果好或者说对梯度小的样本进行进一步学习对改善结果精度帮助其实并不大。<br>GOSS的计算步骤如下：<br>•    根据样本的梯度将样本降序排序。<br>•    保留前n个数据样本，作为数据子集z1。<br>•    对于剩下的数据的样本，随机采样获得大小为m的数据子集Z2。<br>•    计算信息增益时对采样的Z2样本的梯度数据乘以（1-n）/m（目的是不改变原数据的分布）</p>
<h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><p>Bagging(随机森林): 从原始样本集中抽取训练集。每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行k轮抽取，得到k个训练集。（k个训练集之间是相互独立的）<br>每次使用一个训练集得到一个模型，k个训练集共得到k个模型。（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等）<br>对分类问题：将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。（所有模型的重要性相同）<br>数据集 63.2%用 36.8%未用 (〖1-1/m)〗^m→1/e=0.368<br>boosting:<br>AdaBoosting方式每次使用的是全部的样本，每轮训练改变样本的权重。下一轮训练的目标是找到一个函数f 来拟合上一轮的残差。当残差足够小或者达到设置的最大迭代次数则停止。Boosting会减小在上一轮训练正确的样本的权重，增大错误样本的权重。（对的残差小，错的残差大）<br>梯度提升的Boosting方式是使用代价函数对上一轮训练出的模型函数f的偏导来拟合残差。<br>Bagging和Boosting的区别：<br>1）样本选择上：<br>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。<br>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。<br>2）样例权重：<br>Bagging：使用均匀取样，每个样例的权重相等<br>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。<br>3）预测函数：<br>Bagging：所有预测函数的权重相等。<br>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。<br>4）并行计算：<br>Bagging：各个预测函数可以并行生成<br>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。<br>5）这个很重要面试被问到了</p>
<p>Stacking<br>Stacking的主要思想是训练模型来学习使用底层学习器的预测结果，下图是一个5折stacking中基模型在所有数据集上生成预测结果的过程，次学习器会基于模型的预测结果进行再训练，单个基模型生成预测结果的过程是：<br>         *首先将所有数据集生成测试集和训练集（假如训练集为10000,测试集为2500行），那么上层会进行5折交叉检验，使用训练集中的8000条作为喂养集，剩余2000行作为验证集（橙色）<br>每次验证相当于使用了蓝色的8000条数据训练出一个模型，使用模型对验证集进行验证得到2000条数据，并对测试集进行预测，得到2500条数据，这样经过5次交叉检验，可以得到中间的橙色的5*2000条验证集的结果(相当于每条数据的预测结果)，5*2500条测试集的预测结果。            </p>
<p>之后我们会将A1、A2、A3并列在一起成10000行3列的矩阵作为training data,B1、B2、B3合并在一起成2500行3列的矩阵作为testing  data，让下层学习器基于这样的数据进行再训练。<br>       再训练是基于每个基础模型的预测结果作为特征（三个特征），次学习器会学习训练如果往这样的基学习的预测结果上赋予权重w，来使得最后的预测最为准确。<br>以上就是Stacking的思想，进行Stacking集成同样需要基学习器尽量保持独立，效果相近。<br>bagging主要强调的是bootstrap的aggregation，一般是指用整个数据集中部分随机样本训练出多个同类型的模型，然后将这些模型叠加在一起（一般简单的处理就是取均值）。常见的比如tree bagging，random forest，bagging of LR。<br>stacking一般是指用数据集训练出多个不同类似的模型，然后将这些模型的结果组合在一起（对它们的结果取均值，或者加权平均）。</p>
<p>boosting是数据权重，而stacking是分类器权重<br>adaboost：自适应增强，前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一个基分类器。，在每一轮中加入一个新的弱分类器，直到达到迭代次数或阈值。    </p>
<h1 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h1><p>与 PCA 不同，LDA 需要利用类标信息进行降维，是一种监督学习降维技术。<br>一个矩阵和该矩阵的非特征向量相乘是对该向量的旋转变换，如AX1，AX2<br>一个矩阵和该矩阵的特征向量相乘是对该向量的伸缩变换，如AX3<br>PCA算法的主要优点有（非监督降维）：<br>1）仅仅需要以方差衡量信息量，不受数据集以外的因素影响。　<br>2）各主成分之间正交，可消除原始数据成分间的相互影响的因素。<br>3）计算方法简单，主要运算是特征值分解，易于实现。</p>
<p>PCA算法的主要缺点有：<br>1）主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强。<br>2）方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</p>
<p>奇异值分解(singular value decomposition)可以分解任意形状的矩阵, PCA是对方阵操作,所以SVD适用范围更广<br>PCA是对SVD的一个包装和使用，如果我们实现了SVD，那也就自然而然实现了PCA，而且相较于单纯的对ATAATA进行特征值分解只得到一个方向上的PCA更好的地方是，有了SVD，我们就可以得到两个方向的PCA。<br>SVD:<br>在讨论SVD之前先讨论矩阵的特征值分解（EVD），在这里，选择一种特殊的矩阵——对称阵（酉空间中叫hermite矩阵即厄米阵）。对称阵有一个很优美的性质：它总能相似对角化，对称阵不同特征值对应的特征向量两两正交。<br> 上面的特征值分解的A矩阵是对称阵，根据EVD可以找到一个（超）矩形使得变换后还是（超）矩形，也即A可以将一组正交基映射到另一组正交基！那么现在来分析：对任意M N的矩阵，能否找到一组正交基使得经过它变换后还是正交基？答案是肯定的，它就是SVD分解的精髓所在。</p>
</body></html></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Cqz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://mega-cqz.github.io/2020/02/28/mlLearn/">https://mega-cqz.github.io/2020/02/28/mlLearn/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://mega-cqz.github.io">世界で一番おひめさま</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习    </a></div><div class="post_share"><div class="social-share" data-image="/img/Fate.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/02/28/DLLearn/"><img class="prev_cover lazyload" data-src="/img/Fate.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>深度学习</span></div></a></div><div class="next-post pull_right"><a href="/2020/02/28/spring/"><img class="next_cover lazyload" data-src="/img/Fate.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>Spring面试</span></div></a></div></nav></div></main><footer id="footer" style="background-image: url(/img/Fate.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By Cqz</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="true" data-click="true"></script><script id="ribbon_piao" mobile="true" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/click_heart.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/ClickShowText.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"left","width":350,"height":500},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>